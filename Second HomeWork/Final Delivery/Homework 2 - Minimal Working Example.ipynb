{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Artificial Neural Networks and Deep Learning\n","\n","---\n","\n","## Homework 2: Minimal Working Example\n","\n","To make your first submission, follow these steps:\n","1. Create a folder named `[2024-2025] AN2DL/Homework 2` in your Google Drive.\n","2. Upload the `mars_for_students.npz` file to this folder.\n","3. Upload the Jupyter notebook `Homework 2 - Minimal Working Example.ipynb`.\n","4. Load and process the data.\n","5. Implement and train your model.\n","6. Submit the generated `.csv` file to Kaggle.\n"],"metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":["## 🌐 Connect Colab to Google Drive"],"metadata":{"id":"dw_-hFm6bjY6"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/gdrive\")\n","%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 2"],"metadata":{"id":"y2S4GWr3Uoa8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ⚙️ Import Libraries"],"metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO6_Ft_8T56A"},"outputs":[],"source":["import os\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"Keras version: {tfk.__version__}\")\n","print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"]},{"cell_type":"markdown","source":["## ⏳ Load the Data"],"metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":["data = np.load(\"mars_for_students.npz\")\n","\n","training_set = data[\"training_set\"]\n","X_train = training_set[:, 0]\n","y_train = training_set[:, 1]\n","\n","X_test = data[\"test_set\"]\n","\n","print(f\"Training X shape: {X_train.shape}\")\n","print(f\"Training y shape: {y_train.shape}\")\n","print(f\"Test X shape: {X_test.shape}\")"],"metadata":{"id":"pLaoDaG1V1Yg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🛠️ Train and Save the Model"],"metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":["# Add color channel and rescale pixels between 0 and 1\n","X_train = X_train[..., np.newaxis] / 255.0\n","X_test = X_test[..., np.newaxis] / 255.0\n","\n","input_shape = X_train.shape[1:]\n","num_classes = len(np.unique(y_train))\n","\n","print(f\"Input shape: {input_shape}\")\n","print(f\"Number of classes: {num_classes}\")"],"metadata":{"id":"VmnTgJi_OOs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tfkl.Input(shape=input_shape)\n","x = tfkl.Conv2D(filters=num_classes, kernel_size=(1, 1), activation=\"softmax\")(inputs)\n","model = tfk.Model(inputs=inputs, outputs=x, name=\"minimal_working_net\")\n","\n","# Define the MeanIoU ignoring the background class\n","mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False)\n","\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[mean_iou])\n","\n","model.summary()"],"metadata":{"id":"CBkb3TRF1KJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs=1)"],"metadata":{"id":"pMCbSMQ_-XoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n","model_filename = f\"model_{timestep_str}.keras\"\n","model.save(model_filename)\n","del model\n","\n","print(f\"Model saved to {model_filename}\")"],"metadata":{"id":"PtM0ubgdOzG-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 📊 Prepare Your Submission\n","\n","In our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n","\n","\n"],"metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":["# If model_filename is not defined, load the most recent model from Google Drive\n","if \"model_filename\" not in globals() or model_filename is None:\n","    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n","    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n","    if files:\n","        model_filename = files[0]\n","    else:\n","        raise FileNotFoundError(\"No model files found in the current directory.\")"],"metadata":{"id":"BU00iEFcYi_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tfk.models.load_model(model_filename)\n","print(f\"Model loaded from {model_filename}\")"],"metadata":{"id":"FMIq69eWgRmr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = model.predict(X_test)\n","preds = np.argmax(preds, axis=-1)\n","print(f\"Predictions shape: {preds.shape}\")"],"metadata":{"id":"z287uIQ_VGoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def y_to_df(y) -> pd.DataFrame:\n","    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n","    n_samples = len(y)\n","    y_flat = y.reshape(n_samples, -1)\n","    df = pd.DataFrame(y_flat)\n","    df[\"id\"] = np.arange(n_samples)\n","    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n","    return df[cols]"],"metadata":{"id":"SPjMEKqZW5jX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create and download the csv submission file\n","timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n","submission_filename = f\"submission_{timestep_str}.csv\"\n","submission_df = y_to_df(preds)\n","submission_df.to_csv(submission_filename, index=False)\n","\n","from google.colab import files\n","files.download(submission_filename)"],"metadata":{"id":"s18kX1uDconq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  \n","<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n","___\n","Credits: Alberto Archetti 📧 alberto.archetti@polito.it\n","\n","\n","\n","\n","\n","```\n","   Copyright 2024 Alberto Archetti\n","\n","   Licensed under the Apache License, Version 2.0 (the \"License\");\n","   you may not use this file except in compliance with the License.\n","   You may obtain a copy of the License at\n","\n","       http://www.apache.org/licenses/LICENSE-2.0\n","\n","   Unless required by applicable law or agreed to in writing, software\n","   distributed under the License is distributed on an \"AS IS\" BASIS,\n","   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","   See the License for the specific language governing permissions and\n","   limitations under the License.\n","```"],"metadata":{"id":"cQEgmFTPfz1n"}}]}