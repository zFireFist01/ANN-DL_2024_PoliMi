{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10100503,"sourceType":"datasetVersion","datasetId":6204364}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artificial Neural Networks and Deep Learning\n\n---\n\n## Homework 2: Minimal Working Example\n\nTo make your first submission, follow these steps:\n1. Create a folder named `[2024-2025] AN2DL/Homework 2` in your Google Drive.\n2. Upload the `mars_for_students.npz` file to this folder.\n3. Upload the Jupyter notebook `Homework 2 - Minimal Working Example.ipynb`.\n4. Load and process the data.\n5. Implement and train your model.\n6. Submit the generated `.csv` file to Kaggle.\n","metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":"","metadata":{"id":"AoKas3XOP2hg"}},{"cell_type":"markdown","source":"## âš™ï¸ Import Libraries","metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom sklearn.model_selection import train_test_split\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\n#print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-05T18:22:25.165489Z","iopub.execute_input":"2024-12-05T18:22:25.165826Z","iopub.status.idle":"2024-12-05T18:22:28.647181Z","shell.execute_reply.started":"2024-12-05T18:22:25.165792Z","shell.execute_reply":"2024-12-05T18:22:28.646242Z"},"id":"CO6_Ft_8T56A","outputId":"fb5bdf8c-8cf2-40b2-c1f5-908d2293d242","trusted":true},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.16.1\nKeras version: 3.3.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## â³ Load the Data","metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/mars_for_students.npz\")\n\n# Estrazione dei set di dati\ntraining_set = data[\"training_set\"]\nX_t = training_set[:, 0]  # Immagini di training\ny_t = training_set[:, 1]  # Maschere di training\n\n# Identificazione della maschera da escludere\noutlier_mask = y_t[62]\n\n# Funzione per filtrare il training set\ndef remove_outliers(X, y, outlier_mask):\n    mask_indices = [i for i in range(len(y)) if np.array_equal(y[i], outlier_mask)]\n    X_train = np.delete(X, mask_indices, axis=0)\n    y_train = np.delete(y, mask_indices, axis=0)\n    return X_train, y_train, mask_indices\n\n# Rimozione degli outliers\nX_clean, y_clean, removed_indices = remove_outliers(X_t, y_t, outlier_mask)\n\n# Stampa degli indici rimossi\nprint(f\"Indici rimossi: {removed_indices}\")\nprint(f\"Numero di immagini originali: {len(X_t)}\")\nprint(f\"Numero di immagini dopo la rimozione: {len(X_clean)}\")\n\nX_train, X_val, y_train, y_val = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n\nX_train = X_train[..., np.newaxis]\nX_val = X_val[..., np.newaxis]\n\nprint(f\"X_train shape: {X_train.shape}\")  # Dovrebbe essere (20040, 64, 128, 1)\nprint(f\"X_val shape: {X_val.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-05T18:22:32.028463Z","iopub.execute_input":"2024-12-05T18:22:32.029052Z","iopub.status.idle":"2024-12-05T18:22:33.015804Z","shell.execute_reply.started":"2024-12-05T18:22:32.029019Z","shell.execute_reply":"2024-12-05T18:22:33.014762Z"},"id":"pLaoDaG1V1Yg","outputId":"a435f901-1666-487e-9e39-35349549997a","trusted":true},"outputs":[{"name":"stdout","text":"Indici rimossi: [62, 79, 125, 139, 142, 147, 152, 156, 170, 210, 217, 266, 289, 299, 313, 339, 348, 365, 412, 417, 426, 450, 461, 536, 552, 669, 675, 741, 744, 747, 799, 802, 808, 820, 821, 849, 863, 890, 909, 942, 971, 1005, 1057, 1079, 1082, 1092, 1095, 1106, 1119, 1125, 1177, 1194, 1224, 1247, 1248, 1258, 1261, 1262, 1306, 1324, 1365, 1370, 1443, 1449, 1508, 1509, 1519, 1551, 1584, 1588, 1628, 1637, 1693, 1736, 1767, 1768, 1782, 1813, 1816, 1834, 1889, 1925, 1942, 1975, 1979, 2000, 2002, 2086, 2096, 2110, 2111, 2151, 2161, 2222, 2235, 2239, 2242, 2301, 2307, 2350, 2361, 2365, 2372, 2414, 2453, 2522, 2535, 2561, 2609, 2614]\nNumero di immagini originali: 2615\nNumero di immagini dopo la rimozione: 2505\nX_train shape: (2004, 64, 128, 1)\nX_val shape: (501, 64, 128, 1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Aggiunta del canale\n#X_train = np.expand_dims(X_train, axis=-1)\n#X_val = np.expand_dims(X_val, axis=-1)\n\n# Dopo l'aggiunta del canale\nprint(\"\\nDopo l'aggiunta del canale:\")\nprint(f\"X_train shape: {X_train.shape}\")  # Dovrebbe essere (20040, 64, 128, 1)\nprint(f\"X_val shape: {X_val.shape}\")      # Dovrebbe essere (7515, 64, 128, 1)\n\n# Verifica anche il tipo di dati e il range dei valori\nprint(\"\\nInformazioni aggiuntive:\")\nprint(f\"X_train dtype: {X_train.dtype}\")\nprint(f\"X_train min value: {X_train.min()}\")\nprint(f\"X_train max value: {X_train.max()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:22:33.655346Z","iopub.execute_input":"2024-12-05T18:22:33.656048Z","iopub.status.idle":"2024-12-05T18:22:33.683535Z","shell.execute_reply.started":"2024-12-05T18:22:33.656013Z","shell.execute_reply":"2024-12-05T18:22:33.682734Z"}},"outputs":[{"name":"stdout","text":"\nDopo l'aggiunta del canale:\nX_train shape: (2004, 64, 128, 1)\nX_val shape: (501, 64, 128, 1)\n\nInformazioni aggiuntive:\nX_train dtype: float64\nX_train min value: 3.0\nX_train max value: 254.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## ðŸ› ï¸ Train and Save the Model","metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":"# Assuming X_train and X_test are your image datasets\n# Add a channel dimension and normalize pixel values to [0, 1]\n#X_train = X_train[..., np.newaxis] / 255.0\n#X_val = X_val[..., np.newaxis] / 255.0\n\n# Calculate input shape and the number of unique classes in the labels\ninput_shape = X_train.shape[1:]\nnum_classes = 5\n\n# Print the results\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")\nprint(\"X_train shape:\", X_train.shape)  # Should be (batch_size, 64, 128, 3)\nprint(\"X_val shape:\", X_val.shape)      # Should be (batch_size, 64, 128, 3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-05T18:22:36.989795Z","iopub.execute_input":"2024-12-05T18:22:36.990679Z","iopub.status.idle":"2024-12-05T18:22:36.995902Z","shell.execute_reply.started":"2024-12-05T18:22:36.990643Z","shell.execute_reply":"2024-12-05T18:22:36.994996Z"},"id":"lABBQe2V3dVp","outputId":"3d27b178-d743-4e35-9481-b6f9ea1f4887","trusted":true},"outputs":[{"name":"stdout","text":"Input shape: (64, 128, 1)\nNumber of classes: 5\nX_train shape: (2004, 64, 128, 1)\nX_val shape: (501, 64, 128, 1)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Convert grayscale to RGB correctly\n#X_train_rgb = np.repeat(X_train, 3, axis=-1)  # Ensure shape (batch_size, 64, 128, 3)\n#X_val_rgb = np.repeat(X_val, 3, axis=-1)\n#print(\"X_train_rgb shape:\", X_train_rgb.shape)  # Should be (batch_size, 64, 128, 3)\n#print(\"X_test_rgb shape:\", X_val_rgb.shape)    # Should be (batch_size, 64, 128, 3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROpSvACB4Kh6","outputId":"11edc22a-b106-4f6c-c15b-d8001aebcc14","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import (\n    Input, \n    Conv2D,\n    MaxPooling2D,\n    UpSampling2D,\n    Concatenate,\n    BatchNormalization,\n    Activation,\n    Dropout,\n    Multiply\n)\nfrom tensorflow.keras.models import Model\n\ndef conv_block(x, filters, name, kernel_size=(3, 3)):\n    x = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal', name=f'{name}_conv1')(x)\n    x = BatchNormalization(name=f'{name}_bn1')(x)\n    x = Activation('relu', name=f'{name}_act1')(x)\n    x = Dropout(0.1)(x)  # Aggiunto dropout moderato\n    \n    x = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal', name=f'{name}_conv2')(x)\n    x = BatchNormalization(name=f'{name}_bn2')(x)\n    x = Activation('relu', name=f'{name}_act2')(x)\n    return x\n\ndef attention_block(x, filters):\n    # Spatial attention\n    attention = Conv2D(filters, (1, 1), activation='sigmoid')(x)\n    return Multiply()([x, attention])\n\ndef nested_unet(input_shape, num_classes):\n    inputs = Input(input_shape)\n    \n    # Encoder Path con attention\n    x00 = conv_block(inputs, 64, 'x00')\n    x00 = attention_block(x00, 64)\n    p0 = MaxPooling2D((2, 2), name='p0')(x00)\n    \n    x10 = conv_block(p0, 128, 'x10')\n    x10 = attention_block(x10, 128)\n    p1 = MaxPooling2D((2, 2), name='p1')(x10)\n    \n    x20 = conv_block(p1, 256, 'x20')\n    x20 = attention_block(x20, 256)\n    p2 = MaxPooling2D((2, 2), name='p2')(x20)\n    \n    x30 = conv_block(p2, 512, 'x30')\n    x30 = attention_block(x30, 512)\n    p3 = MaxPooling2D((2, 2), name='p3')(x30)\n    \n    # Bridge\n    x40 = conv_block(p3, 1024, 'x40')\n    x40 = attention_block(x40, 1024)\n    \n    # Decoder Path con skip connections migliorate\n    u03 = UpSampling2D((2, 2), name='u03')(x40)\n    x31 = Concatenate(name='cat31')([u03, x30])\n    x31 = conv_block(x31, 512, 'x31')\n    x31 = attention_block(x31, 512)\n    \n    u02 = UpSampling2D((2, 2), name='u02')(x31)\n    x21 = Concatenate(name='cat21')([u02, x20])\n    x21 = conv_block(x21, 256, 'x21')\n    x21 = attention_block(x21, 256)\n    \n    u01 = UpSampling2D((2, 2), name='u01')(x21)\n    x11 = Concatenate(name='cat11')([u01, x10])\n    x11 = conv_block(x11, 128, 'x11')\n    x11 = attention_block(x11, 128)\n    \n    u00 = UpSampling2D((2, 2), name='u00')(x11)\n    x01 = Concatenate(name='cat01')([u00, x00])\n    x01 = conv_block(x01, 64, 'x01')\n    x01 = attention_block(x01, 64)\n    \n    # Output con doppia supervisione\n    coarse_output = Conv2D(num_classes, (1, 1), activation='softmax', name='coarse_output')(x01)\n    \n    fine_pre = Conv2D(num_classes, (1, 1), activation='softmax', name='fine_pre')(x01)\n    attention_map = Conv2D(1, (1, 1), activation='sigmoid', name='attention_map')(x01)\n    fine_output = Multiply(name='fine_output')([fine_pre, attention_map])\n    \n    model = Model(inputs=[inputs], outputs=[coarse_output, fine_output])\n    return model\n\n# Recreate the model\ninput_shape = (64, 128, 1)\nnum_classes = 5\nmodel = nested_unet(input_shape, num_classes)\n\n# Ricrea il modello con i nuovi nomi\nmodel = nested_unet(input_shape, num_classes)\n\n# Stampa i nomi degli output per verifica\nprint(\"New model output names:\", model.output_names)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T18:22:38.925969Z","iopub.execute_input":"2024-12-05T18:22:38.926329Z","iopub.status.idle":"2024-12-05T18:22:40.088101Z","shell.execute_reply.started":"2024-12-05T18:22:38.926297Z","shell.execute_reply":"2024-12-05T18:22:40.087245Z"},"id":"Vqu0EX7CVWPb","trusted":true},"outputs":[{"name":"stdout","text":"New model output names: ListWrapper(['coarse_output', 'fine_output'])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Define custom Mean Intersection Over Union metric\nclass MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n    def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n        if labels_to_exclude is None:\n            labels_to_exclude = [0]  # Default to excluding label 0\n        self.labels_to_exclude = labels_to_exclude\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Convert predictions to class labels\n        y_pred = tf.math.argmax(y_pred, axis=-1)\n\n        # Flatten the tensors\n        y_true = tf.reshape(y_true, [-1])\n        y_pred = tf.reshape(y_pred, [-1])\n\n        # Apply mask to exclude specified labels\n        for label in self.labels_to_exclude:\n            mask = tf.not_equal(y_true, label)\n            y_true = tf.boolean_mask(y_true, mask)\n            y_pred = tf.boolean_mask(y_pred, mask)\n\n        # Update the state\n        return super().update_state(y_true, y_pred, sample_weight)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T18:22:40.249018Z","iopub.execute_input":"2024-12-05T18:22:40.249822Z","iopub.status.idle":"2024-12-05T18:22:40.256010Z","shell.execute_reply.started":"2024-12-05T18:22:40.249788Z","shell.execute_reply":"2024-12-05T18:22:40.255071Z"},"id":"CtVm9jJjArdI","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef focal_loss_with_label_smoothing(alpha=0.25, gamma=2.0, smoothing=0.1):\n    def loss(y_true, y_pred):\n        # Convertiamo y_true in one-hot encoding\n        y_true = tf.cast(y_true, tf.int32)\n        y_true_one_hot = tf.one_hot(tf.squeeze(y_true), depth=5)\n        \n        # Clip predictions per evitare log(0)\n        y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n        \n        # Label smoothing\n        y_true_smooth = y_true_one_hot * (1.0 - smoothing) + smoothing / 5.0\n        \n        # Focal loss\n        ce = -y_true_smooth * K.log(y_pred)\n        weight = alpha * K.pow(1.0 - y_pred, gamma)\n        focal = weight * ce\n        \n        # Media su tutti i pixel\n        return K.mean(K.sum(focal, axis=-1))\n    \n    return loss\n\ndef weighted_focal_loss(alpha=0.25, gamma=2.0):\n    def loss(y_true, y_pred):\n        # Converti y_true in one-hot\n        y_true = tf.cast(y_true, tf.int32)\n        y_true_one_hot = tf.one_hot(tf.squeeze(y_true), depth=5)\n        \n        # Pesi per le classi\n        class_weights = tf.constant([0.1, 1.0, 2.0, 1.5, 2.0])\n        \n        # Focal loss con pesi per classe\n        epsilon = 1e-7\n        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        \n        ce = -y_true_one_hot * tf.math.log(y_pred)\n        weight = alpha * tf.pow(1. - y_pred, gamma)\n        fl = weight * ce * class_weights\n        \n        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-12-05T18:22:41.470736Z","iopub.execute_input":"2024-12-05T18:22:41.471400Z","iopub.status.idle":"2024-12-05T18:22:41.480780Z","shell.execute_reply.started":"2024-12-05T18:22:41.471365Z","shell.execute_reply":"2024-12-05T18:22:41.479849Z"},"id":"q33okXOgdzIu","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Constants\nBATCH_SIZE = 32\nAUTO = tf.data.AUTOTUNE\n    \ndef apply_combined_transform(x, y):\n    \"\"\"Funzione per applicare trasformazioni o preprocessamenti ai dataset.\"\"\"\n    y = tf.expand_dims(y, axis=-1)  # Aggiungi dimensione per il canale\n    \n    return (\n        tf.cast(x, tf.float32) / 255.0,  # Normalizza input\n        {\n            'coarse_output': y,\n            'fine_output': y\n        }\n    )\n\n# Ricrea i dataset\ntrain_ds = (\n    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    .shuffle(BATCH_SIZE * 100, seed=42)\n    .batch(BATCH_SIZE)\n    .map(apply_combined_transform, num_parallel_calls=AUTO)\n    .prefetch(AUTO)\n)\n\nval_ds = (\n    tf.data.Dataset.from_tensor_slices((X_val, y_val))\n    .batch(BATCH_SIZE)\n    .map(apply_combined_transform, num_parallel_calls=AUTO)\n    .prefetch(AUTO)\n) \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T18:22:42.407608Z","iopub.execute_input":"2024-12-05T18:22:42.408442Z","iopub.status.idle":"2024-12-05T18:22:44.308108Z","shell.execute_reply.started":"2024-12-05T18:22:42.408408Z","shell.execute_reply":"2024-12-05T18:22:44.307138Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Compilazione del modello\nmodel.compile(\n    optimizer=tf.keras.optimizers.AdamW(\n        learning_rate=1e-3,\n        weight_decay=1e-4,\n        beta_1=0.9,\n        beta_2=0.999\n    ),\n    loss={\n        'coarse_output': weighted_focal_loss(alpha=0.25, gamma=2.0),\n        'fine_output': weighted_focal_loss(alpha=0.25, gamma=2.0)\n    },\n    loss_weights={\n        'coarse_output': 0.4,\n        'fine_output': 1.0\n    },\n    metrics=['accuracy', MeanIntersectionOverUnion(num_classes=5)]\n)\n\n# Callbacks migliorati\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_fine_output_mean_iou',\n        mode='max',\n        patience=15,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_fine_output_mean_iou',\n        mode='max',\n        factor=0.5,\n        patience=5,\n        min_lr=1e-7,\n        verbose=1\n    )\n]\n\n# Training\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=100,\n    callbacks=callbacks,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:22:44.468411Z","iopub.execute_input":"2024-12-05T18:22:44.469234Z","iopub.status.idle":"2024-12-05T18:35:18.149597Z","shell.execute_reply.started":"2024-12-05T18:22:44.469196Z","shell.execute_reply":"2024-12-05T18:35:18.148568Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733422978.318132     244 service.cc:145] XLA service 0x7b96080042d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733422978.318193     244 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/63\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m52:27\u001b[0m 51s/step - coarse_output_accuracy: 0.1514 - fine_output_mean_iou: 0.0672 - loss: 0.6711","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733423015.079446     244 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - coarse_output_accuracy: 0.2911 - fine_output_mean_iou: 0.1576 - loss: 0.4007","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733423056.039699     244 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_divide_multiply_subtract_fusion_19', 16 bytes spill stores, 16 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_divide_multiply_subtract_fusion_15', 16 bytes spill stores, 16 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_divide_multiply_subtract_fusion_17', 16 bytes spill stores, 16 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 857ms/step - coarse_output_accuracy: 0.2917 - fine_output_mean_iou: 0.1578 - loss: 0.3991 - val_coarse_output_accuracy: 0.1979 - val_fine_output_mean_iou: 0.0656 - val_loss: 1.3223 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - coarse_output_accuracy: 0.3786 - fine_output_mean_iou: 0.2022 - loss: 0.1826 - val_coarse_output_accuracy: 0.1986 - val_fine_output_mean_iou: 0.0656 - val_loss: 0.7290 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.3952 - fine_output_mean_iou: 0.2278 - loss: 0.1597 - val_coarse_output_accuracy: 0.1979 - val_fine_output_mean_iou: 0.0656 - val_loss: 1.2320 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - coarse_output_accuracy: 0.3902 - fine_output_mean_iou: 0.2247 - loss: 0.1503 - val_coarse_output_accuracy: 0.2089 - val_fine_output_mean_iou: 0.1130 - val_loss: 0.7431 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.4438 - fine_output_mean_iou: 0.2639 - loss: 0.1479 - val_coarse_output_accuracy: 0.2159 - val_fine_output_mean_iou: 0.0840 - val_loss: 0.8547 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.5280 - fine_output_mean_iou: 0.3230 - loss: 0.1318 - val_coarse_output_accuracy: 0.2883 - val_fine_output_mean_iou: 0.1361 - val_loss: 0.4033 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.5526 - fine_output_mean_iou: 0.3384 - loss: 0.1171 - val_coarse_output_accuracy: 0.3303 - val_fine_output_mean_iou: 0.1644 - val_loss: 0.3780 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.5447 - fine_output_mean_iou: 0.3401 - loss: 0.1196 - val_coarse_output_accuracy: 0.4957 - val_fine_output_mean_iou: 0.2834 - val_loss: 0.1654 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.5747 - fine_output_mean_iou: 0.3586 - loss: 0.1228 - val_coarse_output_accuracy: 0.4782 - val_fine_output_mean_iou: 0.2791 - val_loss: 0.1867 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.5924 - fine_output_mean_iou: 0.4132 - loss: 0.1079 - val_coarse_output_accuracy: 0.4692 - val_fine_output_mean_iou: 0.2903 - val_loss: 0.1897 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6108 - fine_output_mean_iou: 0.4102 - loss: 0.0962 - val_coarse_output_accuracy: 0.5563 - val_fine_output_mean_iou: 0.3348 - val_loss: 0.1296 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6309 - fine_output_mean_iou: 0.4194 - loss: 0.0998 - val_coarse_output_accuracy: 0.6154 - val_fine_output_mean_iou: 0.3713 - val_loss: 0.1365 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6325 - fine_output_mean_iou: 0.4247 - loss: 0.0928 - val_coarse_output_accuracy: 0.6566 - val_fine_output_mean_iou: 0.4299 - val_loss: 0.1098 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6352 - fine_output_mean_iou: 0.4283 - loss: 0.0893 - val_coarse_output_accuracy: 0.5566 - val_fine_output_mean_iou: 0.3336 - val_loss: 0.1470 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6205 - fine_output_mean_iou: 0.4159 - loss: 0.0969 - val_coarse_output_accuracy: 0.6249 - val_fine_output_mean_iou: 0.4110 - val_loss: 0.1160 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6433 - fine_output_mean_iou: 0.4479 - loss: 0.0835 - val_coarse_output_accuracy: 0.6769 - val_fine_output_mean_iou: 0.4579 - val_loss: 0.0840 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6560 - fine_output_mean_iou: 0.4527 - loss: 0.0805 - val_coarse_output_accuracy: 0.6579 - val_fine_output_mean_iou: 0.4317 - val_loss: 0.0998 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6536 - fine_output_mean_iou: 0.4515 - loss: 0.0737 - val_coarse_output_accuracy: 0.6337 - val_fine_output_mean_iou: 0.4304 - val_loss: 0.1007 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6615 - fine_output_mean_iou: 0.4659 - loss: 0.0738 - val_coarse_output_accuracy: 0.6750 - val_fine_output_mean_iou: 0.4298 - val_loss: 0.1186 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - coarse_output_accuracy: 0.6676 - fine_output_mean_iou: 0.4606 - loss: 0.0706 - val_coarse_output_accuracy: 0.6912 - val_fine_output_mean_iou: 0.4660 - val_loss: 0.0794 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6567 - fine_output_mean_iou: 0.4597 - loss: 0.0796 - val_coarse_output_accuracy: 0.6213 - val_fine_output_mean_iou: 0.4273 - val_loss: 0.0811 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6826 - fine_output_mean_iou: 0.4789 - loss: 0.0657 - val_coarse_output_accuracy: 0.6832 - val_fine_output_mean_iou: 0.4514 - val_loss: 0.0827 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6784 - fine_output_mean_iou: 0.4554 - loss: 0.0676 - val_coarse_output_accuracy: 0.6722 - val_fine_output_mean_iou: 0.4318 - val_loss: 0.0905 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - coarse_output_accuracy: 0.6903 - fine_output_mean_iou: 0.4853 - loss: 0.0643 - val_coarse_output_accuracy: 0.6716 - val_fine_output_mean_iou: 0.4682 - val_loss: 0.0817 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6835 - fine_output_mean_iou: 0.4758 - loss: 0.0667 - val_coarse_output_accuracy: 0.6730 - val_fine_output_mean_iou: 0.4246 - val_loss: 0.1203 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6729 - fine_output_mean_iou: 0.4634 - loss: 0.0715 - val_coarse_output_accuracy: 0.7329 - val_fine_output_mean_iou: 0.4768 - val_loss: 0.0846 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6879 - fine_output_mean_iou: 0.4848 - loss: 0.0590 - val_coarse_output_accuracy: 0.6833 - val_fine_output_mean_iou: 0.4670 - val_loss: 0.0961 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.6935 - fine_output_mean_iou: 0.4833 - loss: 0.0605 - val_coarse_output_accuracy: 0.7002 - val_fine_output_mean_iou: 0.4818 - val_loss: 0.0842 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6755 - fine_output_mean_iou: 0.4657 - loss: 0.0656 - val_coarse_output_accuracy: 0.7236 - val_fine_output_mean_iou: 0.4412 - val_loss: 0.1343 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6947 - fine_output_mean_iou: 0.4840 - loss: 0.0594 - val_coarse_output_accuracy: 0.7409 - val_fine_output_mean_iou: 0.4707 - val_loss: 0.0952 - learning_rate: 0.0010\nEpoch 31/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6877 - fine_output_mean_iou: 0.4840 - loss: 0.0628 - val_coarse_output_accuracy: 0.6777 - val_fine_output_mean_iou: 0.4646 - val_loss: 0.0871 - learning_rate: 0.0010\nEpoch 32/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6877 - fine_output_mean_iou: 0.4882 - loss: 0.0635 - val_coarse_output_accuracy: 0.6731 - val_fine_output_mean_iou: 0.4525 - val_loss: 0.1003 - learning_rate: 0.0010\nEpoch 33/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - coarse_output_accuracy: 0.7048 - fine_output_mean_iou: 0.5171 - loss: 0.0508 - val_coarse_output_accuracy: 0.7252 - val_fine_output_mean_iou: 0.4916 - val_loss: 0.0649 - learning_rate: 0.0010\nEpoch 34/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6905 - fine_output_mean_iou: 0.4932 - loss: 0.0572 - val_coarse_output_accuracy: 0.6895 - val_fine_output_mean_iou: 0.4664 - val_loss: 0.0809 - learning_rate: 0.0010\nEpoch 35/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7031 - fine_output_mean_iou: 0.5007 - loss: 0.0549 - val_coarse_output_accuracy: 0.6775 - val_fine_output_mean_iou: 0.4463 - val_loss: 0.1255 - learning_rate: 0.0010\nEpoch 36/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7146 - fine_output_mean_iou: 0.5144 - loss: 0.0526 - val_coarse_output_accuracy: 0.7154 - val_fine_output_mean_iou: 0.4680 - val_loss: 0.0941 - learning_rate: 0.0010\nEpoch 37/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7200 - fine_output_mean_iou: 0.5426 - loss: 0.0484 - val_coarse_output_accuracy: 0.7415 - val_fine_output_mean_iou: 0.4885 - val_loss: 0.0717 - learning_rate: 0.0010\nEpoch 38/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - coarse_output_accuracy: 0.7268 - fine_output_mean_iou: 0.5338 - loss: 0.0468 - val_coarse_output_accuracy: 0.7184 - val_fine_output_mean_iou: 0.5235 - val_loss: 0.0664 - learning_rate: 0.0010\nEpoch 39/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7258 - fine_output_mean_iou: 0.5682 - loss: 0.0459 - val_coarse_output_accuracy: 0.7155 - val_fine_output_mean_iou: 0.4795 - val_loss: 0.0850 - learning_rate: 0.0010\nEpoch 40/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7106 - fine_output_mean_iou: 0.5246 - loss: 0.0491 - val_coarse_output_accuracy: 0.6317 - val_fine_output_mean_iou: 0.4223 - val_loss: 0.1689 - learning_rate: 0.0010\nEpoch 41/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.6913 - fine_output_mean_iou: 0.4904 - loss: 0.0606 - val_coarse_output_accuracy: 0.7255 - val_fine_output_mean_iou: 0.4823 - val_loss: 0.0778 - learning_rate: 0.0010\nEpoch 42/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7332 - fine_output_mean_iou: 0.5431 - loss: 0.0427 - val_coarse_output_accuracy: 0.6879 - val_fine_output_mean_iou: 0.4804 - val_loss: 0.0718 - learning_rate: 0.0010\nEpoch 43/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - coarse_output_accuracy: 0.7252 - fine_output_mean_iou: 0.5309 - loss: 0.0422\nEpoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7253 - fine_output_mean_iou: 0.5311 - loss: 0.0422 - val_coarse_output_accuracy: 0.7119 - val_fine_output_mean_iou: 0.4608 - val_loss: 0.1026 - learning_rate: 0.0010\nEpoch 44/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7499 - fine_output_mean_iou: 0.5823 - loss: 0.0366 - val_coarse_output_accuracy: 0.7259 - val_fine_output_mean_iou: 0.5048 - val_loss: 0.0650 - learning_rate: 5.0000e-04\nEpoch 45/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - coarse_output_accuracy: 0.7560 - fine_output_mean_iou: 0.5707 - loss: 0.0341 - val_coarse_output_accuracy: 0.7329 - val_fine_output_mean_iou: 0.5105 - val_loss: 0.0684 - learning_rate: 5.0000e-04\nEpoch 46/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - coarse_output_accuracy: 0.7696 - fine_output_mean_iou: 0.5652 - loss: 0.0299 - val_coarse_output_accuracy: 0.7130 - val_fine_output_mean_iou: 0.5040 - val_loss: 0.0698 - learning_rate: 5.0000e-04\nEpoch 47/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7789 - fine_output_mean_iou: 0.6091 - loss: 0.0271 - val_coarse_output_accuracy: 0.7211 - val_fine_output_mean_iou: 0.5181 - val_loss: 0.0666 - learning_rate: 5.0000e-04\nEpoch 48/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - coarse_output_accuracy: 0.7553 - fine_output_mean_iou: 0.5677 - loss: 0.0345\nEpoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7553 - fine_output_mean_iou: 0.5678 - loss: 0.0344 - val_coarse_output_accuracy: 0.7463 - val_fine_output_mean_iou: 0.5076 - val_loss: 0.0690 - learning_rate: 5.0000e-04\nEpoch 49/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.7703 - fine_output_mean_iou: 0.5847 - loss: 0.0275 - val_coarse_output_accuracy: 0.7176 - val_fine_output_mean_iou: 0.5412 - val_loss: 0.0696 - learning_rate: 2.5000e-04\nEpoch 50/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7854 - fine_output_mean_iou: 0.6010 - loss: 0.0250 - val_coarse_output_accuracy: 0.7080 - val_fine_output_mean_iou: 0.5408 - val_loss: 0.0700 - learning_rate: 2.5000e-04\nEpoch 51/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7773 - fine_output_mean_iou: 0.5928 - loss: 0.0254 - val_coarse_output_accuracy: 0.7332 - val_fine_output_mean_iou: 0.5385 - val_loss: 0.0702 - learning_rate: 2.5000e-04\nEpoch 52/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.7861 - fine_output_mean_iou: 0.5899 - loss: 0.0249 - val_coarse_output_accuracy: 0.7235 - val_fine_output_mean_iou: 0.5495 - val_loss: 0.0716 - learning_rate: 2.5000e-04\nEpoch 53/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7847 - fine_output_mean_iou: 0.6170 - loss: 0.0237 - val_coarse_output_accuracy: 0.7525 - val_fine_output_mean_iou: 0.5361 - val_loss: 0.0707 - learning_rate: 2.5000e-04\nEpoch 54/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7892 - fine_output_mean_iou: 0.6254 - loss: 0.0236 - val_coarse_output_accuracy: 0.7385 - val_fine_output_mean_iou: 0.5275 - val_loss: 0.0745 - learning_rate: 2.5000e-04\nEpoch 55/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - coarse_output_accuracy: 0.7784 - fine_output_mean_iou: 0.6005 - loss: 0.0227 - val_coarse_output_accuracy: 0.7405 - val_fine_output_mean_iou: 0.5541 - val_loss: 0.0724 - learning_rate: 2.5000e-04\nEpoch 56/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7868 - fine_output_mean_iou: 0.6239 - loss: 0.0221 - val_coarse_output_accuracy: 0.7428 - val_fine_output_mean_iou: 0.5523 - val_loss: 0.0725 - learning_rate: 2.5000e-04\nEpoch 57/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7903 - fine_output_mean_iou: 0.6058 - loss: 0.0211 - val_coarse_output_accuracy: 0.7075 - val_fine_output_mean_iou: 0.5473 - val_loss: 0.0844 - learning_rate: 2.5000e-04\nEpoch 58/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7817 - fine_output_mean_iou: 0.6223 - loss: 0.0208 - val_coarse_output_accuracy: 0.7233 - val_fine_output_mean_iou: 0.5365 - val_loss: 0.0798 - learning_rate: 2.5000e-04\nEpoch 59/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7893 - fine_output_mean_iou: 0.6246 - loss: 0.0199 - val_coarse_output_accuracy: 0.7399 - val_fine_output_mean_iou: 0.5313 - val_loss: 0.0778 - learning_rate: 2.5000e-04\nEpoch 60/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - coarse_output_accuracy: 0.7832 - fine_output_mean_iou: 0.6573 - loss: 0.0208\nEpoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7834 - fine_output_mean_iou: 0.6573 - loss: 0.0208 - val_coarse_output_accuracy: 0.7510 - val_fine_output_mean_iou: 0.5297 - val_loss: 0.0818 - learning_rate: 2.5000e-04\nEpoch 61/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7939 - fine_output_mean_iou: 0.6693 - loss: 0.0188 - val_coarse_output_accuracy: 0.7405 - val_fine_output_mean_iou: 0.5517 - val_loss: 0.0763 - learning_rate: 1.2500e-04\nEpoch 62/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8113 - fine_output_mean_iou: 0.6686 - loss: 0.0173 - val_coarse_output_accuracy: 0.7304 - val_fine_output_mean_iou: 0.5360 - val_loss: 0.0882 - learning_rate: 1.2500e-04\nEpoch 63/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7970 - fine_output_mean_iou: 0.6756 - loss: 0.0177 - val_coarse_output_accuracy: 0.7465 - val_fine_output_mean_iou: 0.5467 - val_loss: 0.0820 - learning_rate: 1.2500e-04\nEpoch 64/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8008 - fine_output_mean_iou: 0.6778 - loss: 0.0173 - val_coarse_output_accuracy: 0.7463 - val_fine_output_mean_iou: 0.5456 - val_loss: 0.0823 - learning_rate: 1.2500e-04\nEpoch 65/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - coarse_output_accuracy: 0.7932 - fine_output_mean_iou: 0.6686 - loss: 0.0198\nEpoch 65: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.7933 - fine_output_mean_iou: 0.6689 - loss: 0.0198 - val_coarse_output_accuracy: 0.7465 - val_fine_output_mean_iou: 0.5451 - val_loss: 0.0844 - learning_rate: 1.2500e-04\nEpoch 66/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8112 - fine_output_mean_iou: 0.6988 - loss: 0.0170 - val_coarse_output_accuracy: 0.7450 - val_fine_output_mean_iou: 0.5411 - val_loss: 0.0804 - learning_rate: 6.2500e-05\nEpoch 67/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8051 - fine_output_mean_iou: 0.7025 - loss: 0.0168 - val_coarse_output_accuracy: 0.7490 - val_fine_output_mean_iou: 0.5370 - val_loss: 0.0834 - learning_rate: 6.2500e-05\nEpoch 68/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8133 - fine_output_mean_iou: 0.6937 - loss: 0.0154 - val_coarse_output_accuracy: 0.7508 - val_fine_output_mean_iou: 0.5386 - val_loss: 0.0859 - learning_rate: 6.2500e-05\nEpoch 69/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8078 - fine_output_mean_iou: 0.6908 - loss: 0.0158 - val_coarse_output_accuracy: 0.7511 - val_fine_output_mean_iou: 0.5455 - val_loss: 0.0881 - learning_rate: 6.2500e-05\nEpoch 70/100\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - coarse_output_accuracy: 0.8150 - fine_output_mean_iou: 0.6832 - loss: 0.0150\nEpoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - coarse_output_accuracy: 0.8149 - fine_output_mean_iou: 0.6836 - loss: 0.0150 - val_coarse_output_accuracy: 0.7505 - val_fine_output_mean_iou: 0.5490 - val_loss: 0.0864 - learning_rate: 6.2500e-05\nEpoch 70: early stopping\nRestoring model weights from the end of the best epoch: 55.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nmodel_filename = f\"model_{timestep_str}.keras\"\nmodel.save(model_filename)\n\nprint(f\"Model saved to {model_filename}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtM0ubgdOzG-","outputId":"b697eb8d-d741-475b-d8db-631391ba0827","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:35:18.151585Z","iopub.execute_input":"2024-12-05T18:35:18.151880Z","iopub.status.idle":"2024-12-05T18:35:19.571143Z","shell.execute_reply.started":"2024-12-05T18:35:18.151852Z","shell.execute_reply":"2024-12-05T18:35:19.570166Z"}},"outputs":[{"name":"stdout","text":"Model saved to model_241205_183518.keras\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Load test data\ndata = np.load(\"/kaggle/input/mars_for_students.npz\")\ntest_set = data[\"test_set\"]\nX_test = np.expand_dims(test_set, axis=-1)\n\n# Normalize test data\nX_test = X_test.astype('float32') / 255.0\n\n# Get predictions\npredictions = model.predict(X_test)\n# Use the fine output predictions (index 1 for fine_output)\nfine_predictions = predictions[1]  # Use index 1 instead of 'fine_output'\n# Convert to class indices\nfinal_predictions = np.argmax(fine_predictions, axis=-1)","metadata":{"id":"z287uIQ_VGoK","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:36:48.727647Z","iopub.execute_input":"2024-12-05T18:36:48.728284Z","iopub.status.idle":"2024-12-05T18:37:08.308620Z","shell.execute_reply.started":"2024-12-05T18:36:48.728248Z","shell.execute_reply":"2024-12-05T18:37:08.307567Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m314/314\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Create submission DataFrame\ndef y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]\n\n","metadata":{"id":"SPjMEKqZW5jX","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:37:10.167527Z","iopub.execute_input":"2024-12-05T18:37:10.167883Z","iopub.status.idle":"2024-12-05T18:37:10.173125Z","shell.execute_reply.started":"2024-12-05T18:37:10.167851Z","shell.execute_reply":"2024-12-05T18:37:10.172260Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Create and save the submission file\ntimestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(final_predictions)\nsubmission_df.to_csv(submission_filename, index=False)\n\nprint(f\"Submission saved to {submission_filename}\")","metadata":{"id":"s18kX1uDconq","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:37:11.366613Z","iopub.execute_input":"2024-12-05T18:37:11.366975Z","iopub.status.idle":"2024-12-05T18:37:33.370453Z","shell.execute_reply.started":"2024-12-05T18:37:11.366943Z","shell.execute_reply":"2024-12-05T18:37:33.369505Z"}},"outputs":[{"name":"stdout","text":"Submission saved to submission_241205_183711.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"#  \n<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n___\nCredits: Alberto Archetti ðŸ“§ alberto.archetti@polito.it\n\n\n\n\n\n```\n   Copyright 2024 Alberto Archetti\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```","metadata":{"id":"cQEgmFTPfz1n"}}]}