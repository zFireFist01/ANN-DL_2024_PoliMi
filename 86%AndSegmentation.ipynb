{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all GPUs TensorFlow detects\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow detected the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"Name: {details['device_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tensorflow and Keras Version for Local Use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "from keras import layers as tfkl\n",
    "from keras import regularizers\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline\n",
    "\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to Load Data and load the datasets needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Load dataset with TensorFlow Datasets, obtaining dataset info\n",
    "\n",
    "    data = np.load(path)\n",
    "    train_dataset = data['images']\n",
    "    test_dataset= data['labels']\n",
    "\n",
    "    # Taking only 11959 samples since after that is all garbage\n",
    "    train_dataset = train_dataset[:11959]\n",
    "    test_dataset = test_dataset[:11959]\n",
    "\n",
    "    return (train_dataset,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test, y_test) = load_data(\"training_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test.shape)\n",
    "print(\"Test set shape (labels):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug, y_test_aug) = load_data(\"augmented_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug2, y_test_aug2) = load_data(\"augmented_set2.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug2.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug3, y_test_aug3) = load_data(\"augmented_set3.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug3.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug4, y_test_aug4) = load_data(\"augmented_set4.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug4.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different concatenations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different type of concatenations of the datasets\n",
    "X_test_concat = np.concatenate((X_test, X_test_aug), axis=0)\n",
    "y_test_concat = np.concatenate((y_test, y_test_aug), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets \n",
    "X_test_concat2 = np.concatenate((X_test_concat, X_test_aug2), axis=0)\n",
    "y_test_concat2 = np.concatenate((y_test_concat, y_test_aug2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "X_test_concat3 = np.concatenate((X_test_concat, X_test_aug3), axis=0)\n",
    "y_test_concat3 = np.concatenate((y_test_concat, y_test_aug3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets -> All the datasets were made by me \n",
    "X_test_concat_d = np.concatenate((X_test_aug, X_test_aug3), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_aug, y_test_aug3), axis=0)\n",
    "X_test_concat_d = np.concatenate((X_test_concat_d, X_test_aug4), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_concat_d, y_test_aug4), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding\n",
    "y_test_aug = tf.keras.utils.to_categorical(y_test_aug, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug2 = tf.keras.utils.to_categorical(y_test_aug3, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug3 = tf.keras.utils.to_categorical(y_test_aug3, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug4 = tf.keras.utils.to_categorical(y_test_aug4, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat = tf.keras.utils.to_categorical(y_test_concat, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat2 = tf.keras.utils.to_categorical(y_test_concat2, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat3 = tf.keras.utils.to_categorical(y_test_concat3, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat_d = tf.keras.utils.to_categorical(y_test_concat_d, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The First - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise EfficientNetV2B3 model with pretrained weights, for transfer learning\n",
    "efficientnet = tf.keras.applications.EfficientNetV2B3(\n",
    "    include_top=False,\n",
    "    input_shape=(96, 96, 3),\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=False,\n",
    "    classes=8,\n",
    "    classifier_activation=\"softmax\",\n",
    "    name=\"efficientnetv2-b3\",\n",
    ")\n",
    "\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "efficientnet.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "# Specify 'to_file' argument with a path where you have write permissions\n",
    "tfk.utils.plot_model(efficientnet, to_file='/tmp/model.png', expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in MobileNetV3Small to use it solely as a feature extractor\n",
    "efficientnet.trainable = False\n",
    "\n",
    "# Define input layer with shape matching the input images\n",
    "inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n",
    "\n",
    "\n",
    "# This is what we used to do in the previous notebook.\n",
    "# After we did direclty the augmentation on the dataset with an ausiliar python file, we did not need to do it here.\n",
    "\"\"\"\n",
    "# Definisci il pipeline completo di augmentazione\n",
    "augmentation = tf.keras.Sequential([\n",
    "    # Altre augmentazioni indipendenti\n",
    "    tfkl.RandomCrop(height=96, width=96),  # Regola la dimensione del crop se necessario\n",
    "    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tfkl.RandomRotation(0.3),\n",
    "    tfkl.Dropout(0.1),\n",
    "    tfkl.Dropout(0.2),\n",
    "    tfkl.RandomContrast(0.3),\n",
    "    tfkl.RandomZoom(0.15),\n",
    "    tfkl.RandomBrightness(0.1),\n",
    "], name='advanced_preprocessing')\n",
    "\n",
    "\n",
    "#Apply the augmentation pipeline\n",
    "inputs = augmentation(inputs)\n",
    "\"\"\"\n",
    "\n",
    "x = efficientnet(inputs)\n",
    "\n",
    "x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# Add a batch normalization layer\n",
    "x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "x = tfkl.Dropout(0.3, name='dropout')(x)\n",
    "\n",
    "# Add a dense layer with 256 units and GELU activation\n",
    "x = tfkl.Dense(256, activation='gelu', name='dense1')(x)\n",
    "\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm1')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout2')(x)\n",
    "\n",
    "# Add a second dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense2')(x)\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm2')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.2, name='dropout3')(x)\n",
    "\n",
    "# Add a third dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense3')(x)\n",
    "\n",
    "#These are just some other layers that I tried to add to the model, but they did not improve the performance, so I commented them out.\n",
    "'''\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm3')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout4')(x)\n",
    "'''\n",
    "\n",
    "# Add final Dense layer for classification with softmax activation\n",
    "outputs = tfkl.Dense(8, activation='softmax', name='output')(x)\n",
    "\n",
    "# Define the complete model linking input and output\n",
    "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimiser\n",
    "tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "tl_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "tl_history = tl_model.fit(\n",
    "    x=X_test_concat3,\n",
    "    y=y_test_concat3,\n",
    "    batch_size=64,\n",
    "    epochs=7,\n",
    "    validation_data=(X_test_aug2 , y_test_aug2),\n",
    "    callbacks=[tfk.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max', patience=20,\n",
    "        restore_best_weights=True\n",
    "        )]\n",
    ").history\n",
    "\n",
    "# We used this concatenation to train the model with the augmented dataset since it was the best performing one locally and also on codabench.\n",
    "# We focused on the fact that the augmented sets we created were good ones, and that the testing on the augmented sets was really close, \n",
    "# sometimese even underfitting, in respect to the accuracy we obtained on codabench.\n",
    "\n",
    "# Calculate and print the best validation accuracy achieved\n",
    "final_val_accuracy = round(max(tl_history['val_accuracy']) * 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "model_filename = '/Keras Files/Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "tl_model.save(model_filename)\n",
    "\n",
    "# Since we often had problems due to RAM and VRAM usage, we decided to clear the session after the training of the model.\n",
    "# So we save the model in .keras format and then we delete it from the session after the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = tl_model.predict(X_test_aug3)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug3.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "# Delete the model from the session\n",
    "del tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_50.49.keras')\n",
    "ft_model = tfk.models.load_model('/Keras Files/Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the EfficientNetV2B3 model layers as trainable\n",
    "ft_model.get_layer('efficientnetv2-b3').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('efficientnetv2-b3').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 100\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_concat_d,\n",
    "    y = y_test_concat_d,\n",
    "    batch_size = 32,\n",
    "    epochs = 6,\n",
    "    validation_data = (X_test_aug2, y_test_aug2),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_76.17.keras')\n",
    "ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the EfficientNetV2B3 model layers as trainable\n",
    "ft_model.get_layer('efficientnetv2-b3').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('efficientnetv2-b3').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 124\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_concat2,\n",
    "    y = y_test_concat2,\n",
    "    batch_size = 32,\n",
    "    epochs = 3,\n",
    "    validation_data = (X_test_aug4, y_test_aug4),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_96.76.keras')\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = ft_model.predict(X_test_aug3[:500])\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug3[:500].argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also tried segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "images = X_test_aug3[:500] # Assuming images are stored under the key 'images'\n",
    "labels = y_test_aug3[:500]# Assuming labels are stored under the key 'labels'\n",
    "\n",
    "# Function to apply k-means clustering to an image\n",
    "def cluster_image(image, n_clusters=5):\n",
    "    h, w, c = image.shape\n",
    "    flat_image = image.reshape(-1, c)  # Flatten image to (pixels, channels)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(flat_image)  # Cluster assignment for each pixel\n",
    "    return labels.reshape(h, w), kmeans.cluster_centers_\n",
    "\n",
    "def apply_histogram_equalization(image):\n",
    "    # Ensure the image is in grayscale\n",
    "    if len(image.shape) == 3:  # If the image has multiple channels (e.g., RGB/BGR)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Ensure the image is uint8\n",
    "    if gray.dtype != np.uint8:\n",
    "        gray = (gray * 255).clip(0, 255).astype(np.uint8)  # Scale to [0, 255] and convert to uint8\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Convert back to RGB (optional)\n",
    "    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def segment_nucleus(image):\n",
    "    \"\"\"\n",
    "    Segments nuclei in the given image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): Input image array (H, W, C) in BGR format.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_only (numpy.ndarray): Image containing only the segmented nuclei.\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        raise ValueError(\"Input image is None\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply stronger noise reduction with median filter\n",
    "    denoised = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Use adaptive thresholding to handle varying lighting\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Use morphological operations to remove small artifacts\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    morphed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask for segmented nuclei\n",
    "    mask = np.zeros_like(gray)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        # Adjust area filter based on expected nucleus size\n",
    "        if 200 < area < 5000:  # These thresholds can be tuned\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image to extract only the nuclei\n",
    "    segmented_only = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return segmented_only\n",
    "\n",
    "# Function to evaluate clusters in an image using a trained model\n",
    "def evaluate_clusters(image, image_clusters, cluster_centers, model, confidence_threshold=0.2):\n",
    "    h, w, c = image.shape\n",
    "    significant_mask = np.zeros((h, w), dtype=bool)  # Mask to keep significant clusters\n",
    "    \n",
    "    for cluster_id in range(len(cluster_centers)):\n",
    "        # Create a mask for the current cluster\n",
    "        cluster_mask = (image_clusters == cluster_id)\n",
    "        \n",
    "        # Reconstruct the image with only this cluster\n",
    "        reconstructed_image = np.zeros_like(image)\n",
    "        reconstructed_image[cluster_mask] = image[cluster_mask]\n",
    "        \n",
    "        # Classify the reconstructed image\n",
    "        prediction = model.predict(reconstructed_image[np.newaxis, ...])  # Add batch dimension\n",
    "        confidence = np.max(prediction)  # Get max confidence\n",
    "        \n",
    "        # If confidence is high, keep this cluster\n",
    "        if confidence > confidence_threshold:\n",
    "            significant_mask = significant_mask | cluster_mask\n",
    "    \n",
    "    return significant_mask\n",
    "\n",
    "# Function to reconstruct an image based on the significant mask\n",
    "def reconstruct_image(image, significant_mask):\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    filtered_image[significant_mask] = image[significant_mask]\n",
    "    return filtered_image\n",
    "\n",
    "# Apply the pipeline to the dataset\n",
    "filtered_images = []\n",
    "filtered_labels = []\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "\n",
    "    '''\n",
    "    print(f\"Processing image {idx+1}/{len(images)}\")\n",
    "    image_clusters, cluster_centers = cluster_image(image, n_clusters=15)  # Adjust n_clusters as needed\n",
    "    significant_mask = evaluate_clusters(image, image_clusters, cluster_centers, ft_model, confidence_threshold=0.2)\n",
    "    filtered_image = reconstruct_image(image, significant_mask)\n",
    "    filtered_images.append(filtered_image)\n",
    "    filtered_labels.append(labels[idx])  # Keep the original label\n",
    "    '''\n",
    "\n",
    "    prediction = ft_model.predict(image[np.newaxis, ...])   # Add batch dimension\n",
    "    confidence = np.max(prediction)  # Get max confidence\n",
    "        \n",
    "        # If confidence is high, keep this cluster\n",
    "    if confidence > 0.90:\n",
    "            \n",
    "            filtered_images.append(image)\n",
    "            filtered_labels.append(labels[idx]) \n",
    "                                   \n",
    "    else:\n",
    "        \n",
    "        print(\"ko\")\n",
    "        equalized_image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Plot the original and equalized images\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(equalized_image)\n",
    "        plt.title(\"Equalized Image\")\n",
    "        plt.axis(\"off\")\n",
    "        filtered_images.append( apply_histogram_equalization(image))\n",
    "        filtered_labels.append(labels[idx]) \n",
    "\n",
    "\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "filtered_images = np.array(filtered_images)\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = ft_model.predict(filtered_images)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = filtered_labels.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: model.py\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the internal state of the model. Note that the __init__\n",
    "        method cannot accept any arguments.\n",
    "\n",
    "        The following is an example loading the weights of a pre-trained\n",
    "        model.\n",
    "        \"\"\"\n",
    "        self.neural_network = tfk.models.load_model('Blood_Cells_MobileNetV3S_97.58.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels corresponding to the input X. Note that X is a numpy\n",
    "        array of shape (n_samples, 96, 96, 3) and the output should be a numpy\n",
    "        array of shape (n_samples,). Therefore, outputs must no be one-hot\n",
    "        encoded.\n",
    "\n",
    "        The following is an example of a prediction from the pre-trained model\n",
    "        loaded in the __init__ method.\n",
    "        \"\"\"\n",
    "        preds = self.neural_network.predict(X)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = f'Outputs/submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Add files to the zip command if needed\n",
    "# The original path was incorrect. Using f-string to format correctly.\n",
    "!zip {filename} model.py Blood_Cells_MobileNetV3S_97.58.keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
