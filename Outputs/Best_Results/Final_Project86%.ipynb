{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all GPUs TensorFlow detects\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow detected the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"Name: {details['device_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tensorflow and Keras Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "from keras import layers as tfkl\n",
    "from keras import regularizers\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline\n",
    "\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to Load Data and load the datasets needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Load dataset with TensorFlow Datasets, obtaining dataset info\n",
    "\n",
    "    data = np.load(path)\n",
    "    train_dataset = data['images']\n",
    "    test_dataset= data['labels']\n",
    "\n",
    "    train_dataset = train_dataset[:11959]\n",
    "    test_dataset = test_dataset[:11959]\n",
    "\n",
    "    return (train_dataset,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test, y_test) = load_data(\"training_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test.shape)\n",
    "print(\"Test set shape (labels):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug, y_test_aug) = load_data(\"augmented_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug2, y_test_aug2) = load_data(\"augmented_set2.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug2.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug2 = tf.keras.utils.to_categorical(y_test_aug2, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug3, y_test_aug3) = load_data(\"augmented_set3.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug3.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug4, y_test_aug4) = load_data(\"augmented_set4.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug4.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug4 = tf.keras.utils.to_categorical(y_test_aug4, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different type of concatenations of the datasets\n",
    "X_test_concat = np.concatenate((X_test, X_test_aug), axis=0)\n",
    "y_test_concat = np.concatenate((y_test, y_test_aug), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets \n",
    "X_test_concat2 = np.concatenate((X_test_concat, X_test_aug2), axis=0)\n",
    "y_test_concat2 = np.concatenate((y_test_concat, y_test_aug2), axis=0)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat2 = tf.keras.utils.to_categorical(y_test_concat2, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "X_test_concat3 = np.concatenate((X_test_concat, X_test_aug3), axis=0)\n",
    "y_test_concat3 = np.concatenate((y_test_concat, y_test_aug3), axis=0)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat3 = tf.keras.utils.to_categorical(y_test_concat3, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets -> All the datasets were made by me \n",
    "X_test_concat_d = np.concatenate((X_test_aug, X_test_aug3), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_aug, y_test_aug3), axis=0)\n",
    "X_test_concat_d = np.concatenate((X_test_concat_d, X_test_aug4), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_concat_d, y_test_aug4), axis=0)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat_d = tf.keras.utils.to_categorical(y_test_concat_d, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding\n",
    "y_test_aug = tf.keras.utils.to_categorical(y_test_aug, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug3 = tf.keras.utils.to_categorical(y_test_aug3, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_aug4 = tf.keras.utils.to_categorical(y_test_aug4, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat = tf.keras.utils.to_categorical(y_test_concat, num_classes=num_classes)\n",
    "\n",
    "# One-hot Encoding\n",
    "y_test_concat2 = tf.keras.utils.to_categorical(y_test_concat2, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The First - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise MobileNetV3Small model with pretrained weights, for transfer learning\n",
    "mobilenet = tf.keras.applications.EfficientNetV2B3(\n",
    "    include_top=False,\n",
    "    input_shape=(96, 96, 3),\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=False,\n",
    "    classes=8,\n",
    "    classifier_activation=\"softmax\",\n",
    "    name=\"efficientnetv2-b3\",\n",
    ")\n",
    "\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "mobilenet.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "# Specify 'to_file' argument with a path where you have write permissions\n",
    "tfk.utils.plot_model(mobilenet, to_file='/tmp/model.png', expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in MobileNetV3Small to use it solely as a feature extractor\n",
    "mobilenet.trainable = False\n",
    "\n",
    "# Define input layer with shape matching the input images\n",
    "inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n",
    "\n",
    "\"\"\"\n",
    "# Definisci il pipeline completo di augmentazione\n",
    "augmentation = tf.keras.Sequential([\n",
    "    # Altre augmentazioni indipendenti\n",
    "    tfkl.RandomCrop(height=96, width=96),  # Regola la dimensione del crop se necessario\n",
    "    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tfkl.RandomRotation(0.3),\n",
    "    tfkl.Dropout(0.1),\n",
    "    tfkl.Dropout(0.2),\n",
    "    tfkl.RandomContrast(0.3),\n",
    "    tfkl.RandomZoom(0.15),\n",
    "    tfkl.RandomBrightness(0.1),\n",
    "], name='advanced_preprocessing')\n",
    "\n",
    "\n",
    "#Apply the augmentation pipeline\n",
    "inputs = augmentation(inputs)\n",
    "\"\"\"\n",
    "\n",
    "# Pass augmented inputs through the MobileNetV3Small feature extractor\n",
    "x = mobilenet(inputs)\n",
    "\n",
    "x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# Add a batch normalization layer\n",
    "x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "x = tfkl.Dropout(0.3, name='dropout')(x)\n",
    "\n",
    "# Add a dense layer with 256 units and GELU activation\n",
    "x = tfkl.Dense(256, activation='gelu', name='dense1')(x)\n",
    "\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm1')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout2')(x)\n",
    "\n",
    "# Add a second dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense2')(x)\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm2')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.2, name='dropout3')(x)\n",
    "\n",
    "# Add a third dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense3')(x)\n",
    "'''\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm3')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout4')(x)\n",
    "'''\n",
    "# Add final Dense layer for classification with softmax activation\n",
    "outputs = tfkl.Dense(8, activation='softmax', name='output')(x)\n",
    "\n",
    "# Define the complete model linking input and output\n",
    "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimiser\n",
    "tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "tl_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "tl_history = tl_model.fit(\n",
    "    x=X_test_concat3,\n",
    "    y=y_test_concat3,\n",
    "    batch_size=64,\n",
    "    epochs=7,\n",
    "    validation_data=(X_test_aug2 , y_test_aug2),\n",
    "    callbacks=[tfk.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max', patience=20,\n",
    "        restore_best_weights=True\n",
    "        )]\n",
    ").history\n",
    "\n",
    "# Calculate and print the best validation accuracy achieved\n",
    "final_val_accuracy = round(max(tl_history['val_accuracy']) * 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "tl_model.save(model_filename)\n",
    "\n",
    "del tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = tl_model.predict(X_test_aug3)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug3.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_50.49.keras')\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MobileNetV3Small model layers as trainable\n",
    "ft_model.get_layer('efficientnetv2-b3').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('efficientnetv2-b3').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 100\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_concat_d,\n",
    "    y = y_test_concat_d,\n",
    "    batch_size = 32,\n",
    "    epochs = 6,\n",
    "    validation_data = (X_test_aug2, y_test_aug2),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_76.17.keras')\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MobileNetV3Small model layers as trainable\n",
    "ft_model.get_layer('efficientnetv2-b3').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('efficientnetv2-b3').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 124\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731521848.635420   12267 service.cc:146] XLA service 0x713088022440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731521848.635446   12267 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   5/1122\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - accuracy: 0.8507 - loss: 0.6357 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731521859.513434   12267 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1122/1122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 42ms/step - accuracy: 0.8463 - loss: 0.5739 - val_accuracy: 0.9696 - val_loss: 0.1855\n",
      "Epoch 2/3\n",
      "\u001b[1m1122/1122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 27ms/step - accuracy: 0.8737 - loss: 0.4815 - val_accuracy: 0.9676 - val_loss: 0.1869\n",
      "Epoch 3/3\n",
      "\u001b[1m1122/1122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 27ms/step - accuracy: 0.8930 - loss: 0.4225 - val_accuracy: 0.9758 - val_loss: 0.1605\n",
      "Final validation accuracy: 97.58%\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_concat2,\n",
    "    y = y_test_concat2,\n",
    "    batch_size = 32,\n",
    "    epochs = 3,\n",
    "    validation_data = (X_test_aug4, y_test_aug4),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: model.py\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the internal state of the model. Note that the __init__\n",
    "        method cannot accept any arguments.\n",
    "\n",
    "        The following is an example loading the weights of a pre-trained\n",
    "        model.\n",
    "        \"\"\"\n",
    "        self.neural_network = tfk.models.load_model('Blood_Cells_MobileNetV3S_97.58.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels corresponding to the input X. Note that X is a numpy\n",
    "        array of shape (n_samples, 96, 96, 3) and the output should be a numpy\n",
    "        array of shape (n_samples,). Therefore, outputs must no be one-hot\n",
    "        encoded.\n",
    "\n",
    "        The following is an example of a prediction from the pre-trained model\n",
    "        loaded in the __init__ method.\n",
    "        \"\"\"\n",
    "        preds = self.neural_network.predict(X)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.py (deflated 54%)\n",
      "  adding: Blood_Cells_MobileNetV3S_97.58.keras (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "filename = f'Outputs/submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Add files to the zip command if needed\n",
    "# The original path was incorrect. Using f-string to format correctly.\n",
    "!zip {filename} model.py Blood_Cells_MobileNetV3S_97.58.keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
