{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7DkPT6mHsng"
   },
   "source": [
    "### Clear GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lou4UhZwHsnh"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7QaYBzwHsnh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    # Clear VRAM\n",
    "    tf.keras.backend.clear_session()\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "\n",
    "    # Clear RAM\n",
    "    gc.collect()\n",
    "\n",
    "#This should clear the VRAM and RAM\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4yVdMieF0vz"
   },
   "source": [
    "### Import the Datasets in my drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21k10f0bFxD4",
    "outputId": "d811fc20-c80b-4564-bb97-476ac1df81cf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXiKBamcFwxN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "training_set_path = '/content/drive/My Drive/[2024-2025] AN2DL/Homework 1'\n",
    "folder_path = '/content/drive/My Drive/Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzABAuZdHsnh"
   },
   "source": [
    "### Check GPU Existence and Status\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akAHd3rhHsni",
    "outputId": "9fa30384-fd77-47af-d993-ba3b4f6b185d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all GPUs TensorFlow detects\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow detected the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"Name: {details['device_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwfPKyP2Hsni",
    "outputId": "c1aac6ea-50d8-4e60-da77-8aa797a92195"
   },
   "outputs": [],
   "source": [
    "#This is to check GPU-Status and Usage (works only for NVIDIA GPUs)\n",
    "!nvidia-smi\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg9e8t0JHsni"
   },
   "source": [
    "### Check Tensorflow and Keras Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7XmqVHmHsni"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klXZpkQSHsnj"
   },
   "source": [
    "### Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcveFXEmHsnj",
    "outputId": "34b1e55c-ad7a-410f-c05c-7bd6ad6493f7"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "from keras import layers as tfkl\n",
    "from keras import regularizers\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline\n",
    "\n",
    "#Number of Classes in the Dataset\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1z_lx0dHsnj"
   },
   "source": [
    "### Create a function to Load Data and load the datasets needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkkVHbMCEeGT"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Load dataset from .npz file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Trim dataset to the first 11959 entries and discard the rest\n",
    "    train_dataset = data['images'][:11959].copy()  # Copy to ensure no reference to the original array\n",
    "    test_dataset = data['labels'][:11959].copy()\n",
    "\n",
    "    # Explicitly delete the original data to free up memory\n",
    "    del data\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiBzonbZEeGT",
    "outputId": "87dd813a-dbfd-45c0-b769-0db1ce9c44da"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test, y_test) = load_data(training_set_path + \"/\" +\"training_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test.shape)\n",
    "print(\"Test set shape (labels):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXaEKRN2EeGT",
    "outputId": "26435473-71f1-4592-fb15-34bf8393dfda"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug, y_test_aug) = load_data(folder_path + \"/\" +\"augmented_set.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nid_RAJtEeGT",
    "outputId": "4e490222-b07e-4999-823f-49112d74caa6"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug2, y_test_aug2) = load_data(folder_path + \"/\" +\"augmented_set2.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug2.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzssfKqZEeGU",
    "outputId": "6e3072e1-74fb-4dd6-d902-92d69d26b5c0"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug3, y_test_aug3) = load_data(folder_path + \"/\" +\"augmented_set3.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug3.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfFIicTWEeGU",
    "outputId": "cf66653d-3f67-46fe-d680-244b572cba1e"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug4, y_test_aug4) = load_data(folder_path + \"/\" +\"augmented_set4.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug4.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0q08ZI7GtFIb",
    "outputId": "c3745cae-08d6-4c12-d828-49f545c10bf1"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_aug6, y_test_aug6) = load_data(folder_path + \"/\" +\"augmented_set6.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_aug6.shape)\n",
    "print(\"Test set shape (labels):\", y_test_aug6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIS4CoJCCHr1",
    "outputId": "75972ccb-e614-458f-be4f-da712588b4ed"
   },
   "outputs": [],
   "source": [
    "# Execute function and load data\n",
    "(X_test_kmeans, y_test_kmeans) = load_data(folder_path + \"/\" +\"kmeans_dataset.npz\")\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_kmeans.shape)\n",
    "print(\"Test set shape (labels):\", y_test_kmeans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK4uuAwZHsnk"
   },
   "source": [
    "### Different Combination of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlFUD42AHsnk",
    "outputId": "da3b1a3e-2697-4b9c-b682-6376ba240566"
   },
   "outputs": [],
   "source": [
    "# Create different type of concatenations of the datasets\n",
    "X_test_concat = np.concatenate((X_test, X_test_aug), axis=0)\n",
    "y_test_concat = np.concatenate((y_test, y_test_aug), axis=0)\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_concat.shape)\n",
    "print(\"Test set shape (labels):\", y_test_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj2mLaU2Hsnk",
    "outputId": "6114bf67-dc4d-4533-9dad-dbde97f1530d"
   },
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "X_test_concat2 = np.concatenate((X_test_concat, X_test_aug2), axis=0)\n",
    "y_test_concat2 = np.concatenate((y_test_concat, y_test_aug2), axis=0)\n",
    "\n",
    "print(\"Test set shape (images):\", X_test_concat2.shape)\n",
    "print(\"Test set shape (labels):\", y_test_concat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QleAjQVHsnl"
   },
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "X_test_concat3 = np.concatenate((X_test_concat2, X_test_aug3), axis=0)\n",
    "y_test_concat3 = np.concatenate((y_test_concat2, y_test_aug3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaPB3TdUHsnl"
   },
   "outputs": [],
   "source": [
    "# Concatenate datasets -> All the datasets were made by me\n",
    "X_test_concat_d = np.concatenate((X_test_aug, X_test_aug3), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_aug, y_test_aug3), axis=0)\n",
    "X_test_concat_d = np.concatenate((X_test_concat_d, X_test_aug4), axis=0)\n",
    "y_test_concat_d = np.concatenate((y_test_concat_d, y_test_aug4), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBcsepkVHsnl"
   },
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhcNjKfIHsnl"
   },
   "outputs": [],
   "source": [
    "# Define a function to conditionally one-hot encode a variable if it exists\n",
    "def conditional_one_hot_encode(var_name, num_classes):\n",
    "    if var_name in globals() and globals()[var_name] is not None:\n",
    "        globals()[var_name] = tfk.utils.to_categorical(globals()[var_name], num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Conditionally apply one-hot encoding to each variable\n",
    "conditional_one_hot_encode('y_test_aug', num_classes)\n",
    "conditional_one_hot_encode('y_test_aug2', num_classes)\n",
    "conditional_one_hot_encode('y_test_aug3', num_classes)\n",
    "conditional_one_hot_encode('y_test_aug4', num_classes)\n",
    "conditional_one_hot_encode('y_test_aug6', num_classes)\n",
    "conditional_one_hot_encode('y_test_concat', num_classes)\n",
    "conditional_one_hot_encode('y_test_concat2', num_classes)\n",
    "conditional_one_hot_encode('y_test_concat3', num_classes)\n",
    "conditional_one_hot_encode('y_test_concat_d', num_classes)\n",
    "conditional_one_hot_encode('y_test_kmeans', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7wYjeXNHsnl"
   },
   "source": [
    "### Define The First - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7m8B6pNWHsnl",
    "outputId": "bb40da14-0d6a-4a34-fe2a-1c860fac9b5d"
   },
   "outputs": [],
   "source": [
    "# Initialise MobileNetV3Small model with pretrained weights, for transfer learning\n",
    "mobilenet =  tf.keras.applications.EfficientNetV2B3(\n",
    "    include_top=False,             # Esclude il classificatore finale\n",
    "    input_shape=(96, 96, 3),       # Dimensioni di input\n",
    "    weights=\"imagenet\",            # Pesi preaddestrati su ImageNet\n",
    "    input_tensor=None,             # Tensor di input (lascia None per usare input_shape)\n",
    "    pooling=None,                  # Nessun pooling; specifica 'avg' per GlobalAveragePooling\n",
    "    classes=8,                     # Numero di classi (non usato se include_top=False)\n",
    "    classifier_activation=\"softmax\" # Attivazione del classificatore (non usato se include_top=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "mobilenet.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "# Specify 'to_file' argument with a path where you have write permissions\n",
    "tfk.utils.plot_model(mobilenet, to_file='/tmp/model.png', expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G87Q1ZhDHsnl"
   },
   "outputs": [],
   "source": [
    "# Freeze all layers in MobileNetV3Small to use it solely as a feature extractor\n",
    "mobilenet.trainable = False\n",
    "\n",
    "# Define input layer with shape matching the input images\n",
    "inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n",
    "\n",
    "\"\"\"\n",
    "# Definisci il pipeline completo di augmentazione\n",
    "augmentation = tf.keras.Sequential([\n",
    "    # Altre augmentazioni indipendenti\n",
    "    tfkl.RandomCrop(height=96, width=96),  # Regola la dimensione del crop se necessario\n",
    "    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tfkl.RandomRotation(0.3),\n",
    "    tfkl.Dropout(0.1),\n",
    "    tfkl.Dropout(0.2),\n",
    "    tfkl.RandomContrast(0.3),\n",
    "    tfkl.RandomZoom(0.15),\n",
    "    tfkl.RandomBrightness(0.1),\n",
    "], name='advanced_preprocessing')\n",
    "\n",
    "\n",
    "#Apply the augmentation pipeline\n",
    "inputs = augmentation(inputs)\n",
    "\"\"\"\n",
    "\n",
    "# Pass augmented inputs through the MobileNetV3Small feature extractor\n",
    "x = mobilenet(inputs)\n",
    "\n",
    "x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# Add a batch normalization layer\n",
    "x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "x = tfkl.Dropout(0.4, name='dropout')(x)\n",
    "\n",
    "# Add a dense layer with 256 units and GELU activation\n",
    "x = tfkl.Dense(256, activation='gelu', name='dense1')(x)\n",
    "\n",
    "\n",
    "# Add layer normalizatiFinal_Project.ipynbon\n",
    "x = tfkl.LayerNormalization(name='layer_norm1')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.4, name='dropout2')(x)\n",
    "\n",
    "# Add a second dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense2')(x)\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm2')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout3')(x)\n",
    "\n",
    "# Add a third dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense3')(x)\n",
    "'''\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm3')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout4')(x)\n",
    "'''\n",
    "# Add final Dense layer for classification with softmax activation\n",
    "outputs = tfkl.Dense(8, activation='softmax', name='output')(x)\n",
    "\n",
    "# Define the complete model linking input and output\n",
    "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Lion optimiser\n",
    "tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer= tfk.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "tl_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "HWAOx82RbEJ4",
    "outputId": "5752e988-c4dc-47fa-b784-3b81a9387884"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "input_shape = (96, 96, 3)  # Replace with your input shape\n",
    "output_units = 8\n",
    "\n",
    "# Freeze the MobileNet layers to retain the pretrained features\n",
    "mobilenet.trainable = False\n",
    "\n",
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# Pass the input through MobileNet\n",
    "x = mobilenet(inputs)\n",
    "\n",
    "# Add global average pooling to flatten MobileNet's output\n",
    "x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# Dense layer 0\n",
    "x = tfkl.Dense(256, activation='relu')(x)  # units_dense_0 = 256\n",
    "# No batch normalization after dense_0 (batch_norm_after_dense_0=False)\n",
    "x = tfkl.Dropout(0.3)(x)  # dropout_rate_0 = 0.3\n",
    "\n",
    "# Dense layer 1\n",
    "x = tfkl.Dense(64, activation='relu')(x)  # units_dense_1 = 64\n",
    "x = tfkl.BatchNormalization()(x)  # batch_norm_after_dense_1=True\n",
    "x = tfkl.Dropout(0.4)(x)  # dropout_rate_1 = 0.4\n",
    "\n",
    "# Dense layer 2\n",
    "x = tfkl.Dense(512, activation='relu')(x)  # units_dense_2 = 512\n",
    "x = tfkl.BatchNormalization()(x)  # batch_norm_after_dense_2=True\n",
    "x = tfkl.Dropout(0.3)(x)  # dropout_rate_2 = 0.3\n",
    "\n",
    "# Dense layer 3\n",
    "x = tfkl.Dense(512, activation='relu')(x)  # units_dense_3 = 512\n",
    "# No batch normalization after dense_3 (batch_norm_after_dense_3=False)\n",
    "x = tfkl.Dropout(0.4)(x)  # dropout_rate_3 = 0.4\n",
    "\n",
    "outputs = tfkl.Dense(output_units, activation='softmax')(x)\n",
    "\n",
    "# Build and compile the model\n",
    "best_model = tfk.Model(inputs, outputs)\n",
    "best_model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=0.001),  # learning_rate = 0.001\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )          # Replace with the number of output classes\n",
    "\n",
    "# Summary of the model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qe0qEORBbL60"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnDRduxMHsnl"
   },
   "source": [
    "### Train First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "hg7D7J2NHsnm",
    "outputId": "9bd56d12-eb79-4880-cc85-ebcec8c818aa"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "best_model_hisy = best_model.fit(\n",
    "    x=X_test_concat2,\n",
    "    y=y_test_concat2,\n",
    "    batch_size=64,\n",
    "    epochs=6,\n",
    "    validation_data=(X_test_aug2 , y_test_aug2),\n",
    "    callbacks=[tfk.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max', patience=10,\n",
    "        restore_best_weights=True\n",
    "        )]\n",
    ").history\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `history` is the output of `model.fit()`\n",
    "def plot_loss_curves(history):\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss_curves(tl_history )\n",
    "\n",
    "# Calculate and print the best validation accuracy achieved\n",
    "final_val_accuracy = round(max(tl_history['val_accuracy']) * 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "#model_filename = 'Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "#tl_model.save(model_filename)\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "tl_model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdpkUC0igEu3",
    "outputId": "aebbab70-8aba-4404-dda2-09cb32dd107f"
   },
   "outputs": [],
   "source": [
    "# Calculate and print the best validation accuracy achieved\n",
    "final_val_accuracy = round(max(best_model_hisy['val_accuracy']) * 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "#model_filename = 'Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "#tl_model.save(model_filename)\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_' + str(final_val_accuracy) + '.keras'\n",
    "best_model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwmdyU0i8UlW"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner\n",
    "from  keras_tuner import HyperModel\n",
    "from  keras_tuner.tuners import Hyperband\n",
    "\n",
    "# Define a custom HyperModel for automatic model order selection\n",
    "class ModelOrderHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        inputs = tfk.Input(shape=self.input_shape, name='input_layer')\n",
    "\n",
    "        # MobileNetV3Small as a feature extractor\n",
    "        mobilenet = tf.keras.applications.MobileNetV3Small(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        mobilenet.trainable = False  # Freeze the base model\n",
    "        x = mobilenet(inputs)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "        # Add batch normalization\n",
    "        if hp.Boolean('batch_norm_before_dense'):\n",
    "            x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "        # Dynamically add dense layers\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 5)):\n",
    "            x = tfkl.Dense(\n",
    "                units=hp.Choice(f'units_dense_{i}', [64, 128, 256, 512]),\n",
    "                activation='gelu',\n",
    "                name=f'dense_{i}'\n",
    "            )(x)\n",
    "            if hp.Boolean(f'batch_norm_after_dense_{i}'):\n",
    "                x = tfkl.BatchNormalization(name=f'batch_norm_{i}')(x)\n",
    "            x = tfkl.Dropout(\n",
    "                rate=hp.Float(f'dropout_rate_{i}', 0.2, 0.5, step=0.1),\n",
    "                name=f'dropout_{i}'\n",
    "            )(x)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = tfkl.Dense(\n",
    "            self.num_classes, activation='softmax', name='output'\n",
    "        )(x)\n",
    "\n",
    "        # Define and compile the model\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='model')\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "            ),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "# Set up Hyperband Tuner\n",
    "input_shape = (96, 96, 3)\n",
    "num_classes = 8\n",
    "\n",
    "hypermodel = ModelOrderHyperModel(input_shape, num_classes)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir',\n",
    "    project_name='model_order_selection'\n",
    ")\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(\n",
    "   X_test_concat2, y_test_concat2,\n",
    "    validation_data=(X_test_aug2, y_test_aug2),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters and build the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vvfy_vjwHsnn"
   },
   "source": [
    "### Test the First - Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knaoCC7MHsnn"
   },
   "outputs": [],
   "source": [
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = best_model.predict(X_test_aug4)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug4.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDKxWaefHsnn"
   },
   "source": [
    "### First Fine - Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfK70LvCHsnn"
   },
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_54.35.keras')\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6OBf5tXHsnn"
   },
   "outputs": [],
   "source": [
    "# Set the MobileNetV3Small model layers as trainable\n",
    "ft_model.get_layer('efficientnetv2-b3').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('efficientnetv2-b3').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aomp12LRHsnn"
   },
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 124\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('efficientnetv2-b3').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Ow8u8vHsnn"
   },
   "outputs": [],
   "source": [
    "# Compile the model with categorical cross-entropy loss and Adam optimiser\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "M7_xqnKPHsnn",
    "outputId": "11092b06-f40d-4b4c-b346-00bad6332097"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_concat_d,\n",
    "    y = y_test_concat_d,\n",
    "    batch_size = 32,\n",
    "    epochs = 7,\n",
    "    validation_data = (X_test_aug2, y_test_aug2),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = tl_model.predict(X_test_aug6)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug6.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "del tl_model\n",
    "\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxRd-Pn7Hsnn"
   },
   "source": [
    "### Second Fine - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "8PcCtEoBHsnn",
    "outputId": "18323f06-2cb7-42d3-808d-fa06a729e794"
   },
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('/content/Blood_Cells_MobileNetV3S_72.21.keras')\n",
    "#ft_model = tfk.models.load_model('Blood_Cells_MobileNetV3S_'+ str(final_val_accuracy) + '.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkXX9nrSHsnn"
   },
   "outputs": [],
   "source": [
    "# Set the MobileNetV3Small model layers as trainable\n",
    "ft_model.get_layer('convnext_xlarge').trainable = True\n",
    "\n",
    "# Set all MobileNetV3Small layers as non-trainable\n",
    "for layer in ft_model.get_layer('convnext_xlarge').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_xlarge').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True\n",
    "        print(i, layer.name, type(layer).__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YFgJNcLhHsnn",
    "outputId": "ea90a50d-a871-4f0c-ccb0-09aa7ae0a10b"
   },
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 70\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_xlarge').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layer indices, names, and trainability status\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_xlarge').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "ft_model.summary(expand_nested=True)\n",
    "\n",
    "# Display model architecture with layer shapes and trainable parameters\n",
    "tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmqkBOPrHsnn"
   },
   "outputs": [],
   "source": [
    "# Compile the model with categorical cross-entropy loss and Adam optimiser\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBlgqDz-Hsnn"
   },
   "outputs": [],
   "source": [
    "# Enable mixed precision\n",
    "tfk.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "kMSjUmUoHsnn",
    "outputId": "5fc955f8-aae4-4c1b-84a8-d7035065601d"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_test_aug5,\n",
    "    y = X_test_aug5,\n",
    "    batch_size = 64,\n",
    "    epochs = 5,\n",
    "    validation_data = (X_test_aug6, y_test_aug6),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=False)]\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "ft_model.save(model_filename)\n",
    "\n",
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = ft_model.predict(X_test_aug2)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug2.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "\n",
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = ft_model.predict(X_test_aug3)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test_aug3.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMEcNOVsHsno"
   },
   "source": [
    "### Submit Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UlslbgZHsno"
   },
   "outputs": [],
   "source": [
    "# Initialise MobileNetV3Small model with pretrained weights, for transfer learning\n",
    "mobilenetf = tf.keras.applications.EfficientNetV2B3(\n",
    "    include_top=False,\n",
    "    input_shape=(96, 96, 3),\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=False,\n",
    "    classes=8,\n",
    "    classifier_activation=\"softmax\",\n",
    "    name=\"efficientnetv2-b3\",\n",
    ")\n",
    "\n",
    "# Freeze all layers in MobileNetV3Small to use it solely as a feature extractor\n",
    "mobilenetf.trainable = False\n",
    "\n",
    "# Define input layer with shape matching the input images\n",
    "inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n",
    "\n",
    "# Pass augmented inputs through the MobileNetV3Small feature extractor\n",
    "x = mobilenetf(inputs)\n",
    "\n",
    "x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# Add a batch normalization layer\n",
    "x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "x = tfkl.Dropout(0.4, name='dropout')(x)\n",
    "\n",
    "# Add a dense layer with 256 units and GELU activation\n",
    "x = tfkl.Dense(256, activation='gelu', name='dense1')(x)\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm1')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.4, name='dropout2')(x)\n",
    "\n",
    "# Add a second dense layer with 128 un load_data(\"training_set.npz\")its and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense2')(x)\n",
    "\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm2')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.4, name='dropout3')(x)\n",
    "\n",
    "# Add a third dense layer with 128 units and GELU activation\n",
    "x = tfkl.Dense(128, activation='gelu', name='dense3')(x)\n",
    "'''\n",
    "# Add layer normalization\n",
    "x = tfkl.LayerNormalization(name='layer_norm3')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = tfkl.Dropout(0.3, name='dropout4')(x)\n",
    "'''\n",
    "# Add final Dense layer for classification with softmax activation\n",
    "outputs = tfkl.Dense(8, activation='softmax', name='output')(x)\n",
    "\n",
    "# Define the complete model linking input and output\n",
    "tlf_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimiser\n",
    "tlf_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "\n",
    "# Load the saved weights\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras.weights.h5'  # replace <final_val_accuracy> with the actual accuracy\n",
    "tlf_model.load_weights(model_filename)\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'Blood_Cells_MobileNetV3S_'+str(final_val_accuracy)+'.keras'\n",
    "tlf_model.save(model_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bgrkr0cVHsno"
   },
   "outputs": [],
   "source": [
    "# file: model.py\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRs3RtsQHsno",
    "outputId": "14b86593-bd8a-417c-a291-e76500b7db48"
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the internal state of the model. Note that the __init__\n",
    "        method cannot accept any arguments.\n",
    "\n",
    "        The following is an example loading the weights of a pre-trained\n",
    "        model.\n",
    "        \"\"\"\n",
    "        self.neural_network = tfk.models.load_model('Blood_Cells_MobileNetV3S_ 96.28.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels corresponding to the input X. Note that X is a numpy\n",
    "        array of shape (n_samples, 96, 96, 3) and the output should be a numpy\n",
    "        array of shape (n_samples,). Therefore, outputs must no be one-hot\n",
    "        encoded.\n",
    "\n",
    "        The following is an example of a prediction from the pre-trained model\n",
    "        loaded in the __init__ method.\n",
    "        \"\"\"\n",
    "        preds = self.neural_network.predict(X)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nse5OExwHsno",
    "outputId": "a04e4c7e-4163-487c-f8a5-6c0667e506e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Add files to the zip command if needed\n",
    "# The original path was incorrect. Using f-string to format correctly.\n",
    "!zip {filename} model.py Blood_Cells_MobileNetV3S_96.28.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcZkBrTUT85t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Sg9e8t0JHsni"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
