{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Ranger Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranger(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=1e-5, weight_decay=1e-4, sync_period=5, slow_step=0.5, name=\"Ranger\", **kwargs):\n",
    "        # Pass learning_rate directly to the base class initializer\n",
    "        super(Ranger, self).__init__(name=name, learning_rate=learning_rate, **kwargs)\n",
    "        \n",
    "        # Store other parameters\n",
    "        self.weight_decay = weight_decay\n",
    "        self.sync_period = sync_period\n",
    "        self.slow_step = slow_step\n",
    "        self.iterations = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
    "        \n",
    "        # Lookahead slow weights initialization\n",
    "        self.slow_weights = None\n",
    "\n",
    "    def apply_gradients(self, grads_and_vars, name=None, **kwargs):\n",
    "        # Use self.learning_rate directly in apply_gradients\n",
    "        for grad, var in grads_and_vars:\n",
    "            if grad is not None:\n",
    "                if self.weight_decay > 0:\n",
    "                    grad += self.weight_decay * var\n",
    "                var.assign_sub(self.learning_rate * grad)\n",
    "\n",
    "        # Initialize slow weights on the first call\n",
    "        if self.slow_weights is None:\n",
    "            self.slow_weights = [tf.Variable(v, trainable=False) for _, v in grads_and_vars]\n",
    "\n",
    "        # Increment the iteration counter\n",
    "        self.iterations.assign_add(1)\n",
    "\n",
    "        # Apply Lookahead every sync_period steps using tf.cond\n",
    "        def apply_lookahead():\n",
    "            for slow_var, (_, var) in zip(self.slow_weights, grads_and_vars):\n",
    "                slow_var.assign_add(self.slow_step * (var - slow_var))\n",
    "                var.assign(slow_var)\n",
    "            return tf.no_op()  # no-op to satisfy return type requirement\n",
    "\n",
    "        # Check if the current iteration is a sync period\n",
    "        tf.cond(tf.equal(self.iterations % self.sync_period, 0), apply_lookahead, lambda: tf.no_op())\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Ranger, self).get_config()\n",
    "        config.update({\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"sync_period\": self.sync_period,\n",
    "            \"slow_step\": self.slow_step\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Instantiate and use the custom Ranger optimizer\n",
    "optimizer = Ranger(learning_rate=1e-5, weight_decay=1e-4, sync_period=5, slow_step=0.5)\n",
    "optimizer_Adam = tfk.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation \n",
    "(This came afterwards, and it did not provide any increment in the accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "images = X_test_aug3[:500] # Assuming images are stored under the key 'images'\n",
    "labels = y_test_aug3[:500]# Assuming labels are stored under the key 'labels'\n",
    "\n",
    "# Function to apply k-means clustering to an image\n",
    "def cluster_image(image, n_clusters=5):\n",
    "    h, w, c = image.shape\n",
    "    flat_image = image.reshape(-1, c)  # Flatten image to (pixels, channels)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(flat_image)  # Cluster assignment for each pixel\n",
    "    return labels.reshape(h, w), kmeans.cluster_centers_\n",
    "\n",
    "def apply_histogram_equalization(image):\n",
    "    # Ensure the image is in grayscale\n",
    "    if len(image.shape) == 3:  # If the image has multiple channels (e.g., RGB/BGR)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Ensure the image is uint8\n",
    "    if gray.dtype != np.uint8:\n",
    "        gray = (gray * 255).clip(0, 255).astype(np.uint8)  # Scale to [0, 255] and convert to uint8\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Convert back to RGB (optional)\n",
    "    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def segment_nucleus(image):\n",
    "    \"\"\"\n",
    "    Segments nuclei in the given image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): Input image array (H, W, C) in BGR format.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_only (numpy.ndarray): Image containing only the segmented nuclei.\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        raise ValueError(\"Input image is None\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply stronger noise reduction with median filter\n",
    "    denoised = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Use adaptive thresholding to handle varying lighting\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Use morphological operations to remove small artifacts\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    morphed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask for segmented nuclei\n",
    "    mask = np.zeros_like(gray)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        # Adjust area filter based on expected nucleus size\n",
    "        if 200 < area < 5000:  # These thresholds can be tuned\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image to extract only the nuclei\n",
    "    segmented_only = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return segmented_only\n",
    "\n",
    "# Function to evaluate clusters in an image using a trained model\n",
    "def evaluate_clusters(image, image_clusters, cluster_centers, model, confidence_threshold=0.2):\n",
    "    h, w, c = image.shape\n",
    "    significant_mask = np.zeros((h, w), dtype=bool)  # Mask to keep significant clusters\n",
    "    \n",
    "    for cluster_id in range(len(cluster_centers)):\n",
    "        # Create a mask for the current cluster\n",
    "        cluster_mask = (image_clusters == cluster_id)\n",
    "        \n",
    "        # Reconstruct the image with only this cluster\n",
    "        reconstructed_image = np.zeros_like(image)\n",
    "        reconstructed_image[cluster_mask] = image[cluster_mask]\n",
    "        \n",
    "        # Classify the reconstructed image\n",
    "        prediction = model.predict(reconstructed_image[np.newaxis, ...])  # Add batch dimension\n",
    "        confidence = np.max(prediction)  # Get max confidence\n",
    "        \n",
    "        # If confidence is high, keep this cluster\n",
    "        if confidence > confidence_threshold:\n",
    "            significant_mask = significant_mask | cluster_mask\n",
    "    \n",
    "    return significant_mask\n",
    "\n",
    "# Function to reconstruct an image based on the significant mask\n",
    "def reconstruct_image(image, significant_mask):\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    filtered_image[significant_mask] = image[significant_mask]\n",
    "    return filtered_image\n",
    "\n",
    "# Apply the pipeline to the dataset\n",
    "filtered_images = []\n",
    "filtered_labels = []\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "\n",
    "    '''\n",
    "    print(f\"Processing image {idx+1}/{len(images)}\")\n",
    "    image_clusters, cluster_centers = cluster_image(image, n_clusters=15)  # Adjust n_clusters as needed\n",
    "    significant_mask = evaluate_clusters(image, image_clusters, cluster_centers, ft_model, confidence_threshold=0.2)\n",
    "    filtered_image = reconstruct_image(image, significant_mask)\n",
    "    filtered_images.append(filtered_image)\n",
    "    filtered_labels.append(labels[idx])  # Keep the original label\n",
    "    '''\n",
    "\n",
    "    prediction = ft_model.predict(image[np.newaxis, ...])   # Add batch dimension\n",
    "    confidence = np.max(prediction)  # Get max confidence\n",
    "        \n",
    "        # If confidence is high, keep this cluster\n",
    "    if confidence > 0.90:\n",
    "            \n",
    "            filtered_images.append(image)\n",
    "            filtered_labels.append(labels[idx]) \n",
    "                                   \n",
    "    else:\n",
    "        \n",
    "        print(\"ko\")\n",
    "        equalized_image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Plot the original and equalized images\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(equalized_image)\n",
    "        plt.title(\"Equalized Image\")\n",
    "        plt.axis(\"off\")\n",
    "        filtered_images.append( apply_histogram_equalization(image))\n",
    "        filtered_labels.append(labels[idx]) \n",
    "\n",
    "\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "filtered_images = np.array(filtered_images)\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "# Generate predictions on the test set and print a classification report\n",
    "y_pred = ft_model.predict(filtered_images)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = filtered_labels.argmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift, ifft2\n",
    "import cv2\n",
    "\n",
    "# Assuming the data has been loaded into variables\n",
    "# (X_test_aug4, y_test_aug4) = load_data(\"augmented_set4.npz\")\n",
    "\n",
    "# Function to create an adaptive high-pass filter based on the frequency spectrum\n",
    "def adaptive_high_pass_filter(f_transform, threshold_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Generates an adaptive high-pass filter mask based on the frequency spectrum.\n",
    "\n",
    "    Parameters:\n",
    "    - f_transform: The Fourier transform of the image.\n",
    "    - threshold_ratio: Ratio of the average magnitude to set as the cutoff.\n",
    "\n",
    "    Returns:\n",
    "    - mask: High-pass filter mask.\n",
    "    \"\"\"\n",
    "    # Compute magnitude spectrum\n",
    "    magnitude_spectrum = np.abs(f_transform)\n",
    "    \n",
    "    # Compute adaptive threshold based on mean magnitude\n",
    "    adaptive_threshold = magnitude_spectrum.mean() * threshold_ratio\n",
    "    \n",
    "    # Create a mask where frequencies below the threshold are set to 0\n",
    "    mask = magnitude_spectrum > adaptive_threshold\n",
    "    return mask\n",
    "\n",
    "# Process each image in the dataset in-place\n",
    "for i, image in enumerate(X_test_aug4):\n",
    "    # Ensure image is in uint8 format if needed\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "    # Process each color channel separately for color images\n",
    "    if len(image.shape) == 3:  # If image has color channels\n",
    "        filtered_channels = []\n",
    "        \n",
    "        for channel in cv2.split(image):\n",
    "            # Fourier transform for the channel\n",
    "            f_transform = fft2(channel)\n",
    "            f_transform_shifted = fftshift(f_transform)\n",
    "            \n",
    "            # Apply adaptive high-pass filter\n",
    "            adaptive_filter = adaptive_high_pass_filter(f_transform_shifted, threshold_ratio=0.2)\n",
    "            filtered_transform = f_transform_shifted * adaptive_filter\n",
    "            \n",
    "            # Convert back to spatial domain\n",
    "            filtered_channel = np.abs(ifft2(np.fft.ifftshift(filtered_transform)))\n",
    "            filtered_channel = cv2.normalize(filtered_channel, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            \n",
    "            # Append the filtered channel\n",
    "            filtered_channels.append(filtered_channel)\n",
    "        \n",
    "        # Merge channels back into a color image and update in-place\n",
    "        X_test_aug4[i] = cv2.merge(filtered_channels)\n",
    "    \n",
    "    else:  # Grayscale image\n",
    "        # Perform Fourier transform\n",
    "        f_transform = fft2(image)\n",
    "        f_transform_shifted = fftshift(f_transform)\n",
    "        \n",
    "        # Apply adaptive high-pass filter\n",
    "        adaptive_filter = adaptive_high_pass_filter(f_transform_shifted, threshold_ratio=0.2)\n",
    "        filtered_transform = f_transform_shifted * adaptive_filter\n",
    "        \n",
    "        # Convert back to spatial domain and normalize\n",
    "        filtered_image = np.abs(ifft2(np.fft.ifftshift(filtered_transform)))\n",
    "        X_test_aug4[i] = cv2.normalize(filtered_image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner\n",
    "from  keras_tuner import HyperModel\n",
    "from  keras_tuner.tuners import Hyperband\n",
    "\n",
    "# Define a custom HyperModel for automatic model order selection\n",
    "class ModelOrderHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        inputs = tfk.Input(shape=self.input_shape, name='input_layer')\n",
    "\n",
    "        # MobileNetV3Small as a feature extractor\n",
    "        mobilenet = tf.keras.applications.MobileNetV3Small(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        mobilenet.trainable = False  # Freeze the base model\n",
    "        x = mobilenet(inputs)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = tfkl.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "        # Add batch normalization\n",
    "        if hp.Boolean('batch_norm_before_dense'):\n",
    "            x = tfkl.BatchNormalization(name='batch_norm')(x)\n",
    "\n",
    "        # Dynamically add dense layers\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 5)):\n",
    "            x = tfkl.Dense(\n",
    "                units=hp.Choice(f'units_dense_{i}', [64, 128, 256, 512]),\n",
    "                activation='gelu',\n",
    "                name=f'dense_{i}'\n",
    "            )(x)\n",
    "            if hp.Boolean(f'batch_norm_after_dense_{i}'):\n",
    "                x = tfkl.BatchNormalization(name=f'batch_norm_{i}')(x)\n",
    "            x = tfkl.Dropout(\n",
    "                rate=hp.Float(f'dropout_rate_{i}', 0.2, 0.5, step=0.1),\n",
    "                name=f'dropout_{i}'\n",
    "            )(x)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = tfkl.Dense(\n",
    "            self.num_classes, activation='softmax', name='output'\n",
    "        )(x)\n",
    "\n",
    "        # Define and compile the model\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='model')\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "            ),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "# Set up Hyperband Tuner\n",
    "input_shape = (96, 96, 3)\n",
    "num_classes = 8\n",
    "\n",
    "hypermodel = ModelOrderHyperModel(input_shape, num_classes)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir',\n",
    "    project_name='model_order_selection'\n",
    ")\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(\n",
    "   X_test_concat2, y_test_concat2,\n",
    "    validation_data=(X_test_aug2, y_test_aug2),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters and build the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
